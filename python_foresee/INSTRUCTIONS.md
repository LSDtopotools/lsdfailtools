# FORESEE development #

Python software for predicting landslide failures based on precipitation, ground motion data and groundwater pressure. The main outputs of this model are the identified failure locations and the timing of the failure. Additional outputs such as depth of failure and factor of safety can also be obtained.

## Installation ##
1. DOCKER INSTRUCTIONS:

Install Docker on your machine using the following link https://docs.docker.com/get-docker/
(note that these instructions may need administrator privileges to run properly)

Install the lsdfailtools software one of two ways:

To build locally from a local Dockerfile:

- Download the Dockerfile from INSERT LINK

- Place the Dockerfile in a directory then navigate there via the command line and run:

- `docker build --tag lsdft .`

- Ensure that you have already cloned the lsdfailtools repository somewhere on your machine either using git from the command line or by downloading from the github website directly and unzipping it (https://github.com/LSDtopotools/lsdfailtools.git) 
- `sudo docker run -it -v /path/to/your/cloned/repo:/LSDTopoTools -e NASA_USERNAME="username" -e NASA_PASSWORD="password"`

- Note: this requires a an account on the NASA EartData website (https://urs.earthdata.nasa.gov), make a login and password, click in Applications>Authorized Apps> Approve More Applications and select NASA GESDISC DATA ARCHIVE. This will be used in the PRECIPITATION section for downloading precipitaiton data.

To build from DockerHub: ARE WE DOING THIS?

- Create a folder into which to put all the files, then run:

- `docker run --rm -it -v /path/to/your/folder/you/just/made:/LSDTopoTools dockerhub/dockerhub_info`

- This should pull the repository along with setting up your Docker container ready for analysis

* You should now be inside the Docker container at the top directory of your cloned repo ready to begin!

* To escape your docker session at any point use `ctrl-d`

Now you need to install the software.

- Run the following commands:

```bash
python setup.py bdist_wheel
```
```bash
pip install dist/XXX.whl
```
- Where XXX is the name of the wheel generated by the python line!

- Rather than navigating to dist/ to check the name you can just autocomplete this using tab autocomplete e.g. type `pip install dis` then hit tab before enter

- Everything is now ready to run, note you will need to follow these steps everytime you want to use the software.

**ALLDATA_PROCESSING**: Process all the input data: Inclinometers, Piezometers, Precipitation, Sentinel and Cosmo-SKYMed interferometry data.

* The inclinometers and the piezometer data must be obtained from on-site locations or purchased.
* The precipitation data is obtained from the Global Precipitation Measurement Mission by NASA, which is freely available online but requires the creation of a free account in their website.
* If alternative data sources are to be used instead, they must be in a .csv file, with columns indicating the duration of precipitation (s) and the precipitation intensity (mm/s).
* The sentinel interferometry data has been obtained from the University of Cantabria through TELESPAZIO VEGA.  
* The Cosmo-SKYMed interferometry data must be obtained from TELESPAZIO VEGA.



1. INCLINOMETERS

Modify `file_paths_inclinometer.json` to include paths to input and output directories.
Then run the command:

```bash
python Make_shapefiles.py
```

2. PIEZOMETERS

Modify `file_paths_piezometer.json` to include paths to input and output directories.
Then run the command:

```bash
python Make_shapefiles.py
```

3. COMBINED SENTINEL COSMO

Modify `file_paths_combined_sentinel_cosmo.json` to include paths to input and output directories.
Then run the command:

```bash
python Process_combo.py
```

3. PRECIPITATION

Please refer to the README.md file within the Precipitation folder for details of how to obtain the precipitation data.
Below is an example of the command to be used:

```bash
python PPT_CMD_RUN.py --ProdTP GPM_30min --StartDate 2018-01-01 --EndDate 2018-12-31 --ProcessDir ~./mydirectory --SptSlc ~./boundary.shp --OP
```

NOTE: If the user does not require the Sentinel and the Cosmo-SkyMed data to be combined (as per step 2.) and instead only one of the two data sources are to be included for the calibration and the validation process, follow steps 4. or 5. accordingly. This output data will substitute consequent data inputs where InSAR data is required in Calibration, Validation or Visualisation processes.

The README.md file also contains instructions on how to amend additional data to the precipitation data.

4. InSAR_SENTINEL

Modify `file_paths_insar_sentinel.json` to include paths to input and output directories.
Then run the command:

```bash
python Process_sentinel.py
```


5. InSAR_CSK

Modify `file_paths_insar_csk.json` to include paths to input and output directories.
Then run the command:

```bash
python Process_insar_AD.py
python Process_insar_EWV.py
```



**CALIBRATION**

Modify `file_paths_calibration.json` to include paths to input and output directories.
Then run the command:

```bash
python Run_calibration.py
```

**VALIDATION**

Modify `file_paths_validation.json` to include paths to input and output directories.
Then run the command:

```bash
python Run_validation.py
```


**VISUALISATION**

Modify `file_paths_visualisation.json` to include paths to input and output directories.

Then run the command:

```bash
python Final_outputs_visualisation.py
```

To convert the .csv output from the validation file into a point shapefile:
```bash
python convert_csv_to_shapefile.py
```

To convert from a point shapefile to a multipolygon shapefile using Voronoi tessellation:

```bash
python voronoi_from_point_shp.py
```
