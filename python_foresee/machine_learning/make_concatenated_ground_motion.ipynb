{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lsdfailtools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5f1926c69334>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfunctions_ground_motion\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfgm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/exports/csce/datastore/geos/users/s1440040/FORESEE/FORESEE_dev/python_foresee/machine_learning/functions_ground_motion.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlsdfailtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miverson2000\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0miverson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lsdfailtools'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import gdal\n",
    "import datetime\n",
    "import itertools\n",
    "import shapefile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import functions_ground_motion as fgm\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base output directory is /exports/csce/datastore/geos/groups/LSDTopoData/FORESEE/Data/ground_motion_csv/\n"
     ]
    }
   ],
   "source": [
    "with open(\"../file_with_paths.json\") as file_with_paths :\n",
    "    FILE_PATHS = json.load(file_with_paths)\n",
    "\n",
    "print(\"The base output directory is {}\".format(FILE_PATHS[\"ground_motion_csv\"]))\n",
    "\n",
    "ground_motion_dir = FILE_PATHS[\"ground_motion_csv\"]\n",
    "ground_motion_file = ground_motion_dir + \"\"\n",
    "# for later: this is how the ground motion data have been saved\n",
    "#out_dir_csv + 'Timeseries_GroundMotion_pixel'+str(i)+'_'+str(j)+'_failure.csv'\n",
    "\n",
    "\n",
    "precip_dir = FILE_PATHS[\"rain_intensity_caliv_valid\"]\n",
    "out_dir = FILE_PATHS[\"time_series_ml\"]\n",
    "\n",
    "# Here comes the rain again\n",
    "rain_dir = FILE_PATHS[\"rain_dir\"]\n",
    "rain_file = rain_dir + \"2014-01-01_to_2019-12-31_Intensity.csv\"\n",
    "\n",
    "topo_dir = FILE_PATHS[\"topo_dir\"]\n",
    "slopefile = topo_dir + \"eu_dem_AoI_epsg32633_SLOPE.bil\"\n",
    "\n",
    "# road file\n",
    "roaddir = FILE_PATHS[\"road_dir\"]\n",
    "roadfile = roaddir + \"Road_line.shp\" # this is in EPSG:32633\n",
    "\n",
    "merged_ground_motion_distance_dir = FILE_PATHS[\"ground_motion_csv\"]\n",
    "merged_ground_motion_distance_file = merged_ground_motion_distance_dir + \"merged_result.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_dir = FILE_PATHS[\"ground_motion_csv\"]\n",
    "concatenated_file = concatenated_dir + \"combined_failure_pixels.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fgm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-84d21290bd58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mslopearr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixelWidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgeotransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minDs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfgm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENVI_raster_binary_to_2d_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslopefile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fgm' is not defined"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "# Probably load the data on each of the csv files as we process it\n",
    "# so that the data doesn't need to be stored in memory all the time.\n",
    "\n",
    "# create the csv file with all the pixel locations\n",
    "# fgm.make_pxl_csv(ground_motion_dir)\n",
    "\n",
    "# concatenates all csv files\n",
    "# fgm.concatenate_csv_files(ground_motion_dir)\n",
    "\n",
    "\n",
    "\n",
    "# Read the road file\n",
    "road = shapefile.Reader(roadfile)\n",
    "roadline = np.array(road.shapes()[0].points)\n",
    "\n",
    "\n",
    "slopearr, pixelWidth, (geotransform, inDs) = fgm.ENVI_raster_binary_to_2d_array(slopefile)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### read pixel position data ##################\n",
    "\n",
    "ground_motion_pxl = pd.read_csv(ground_motion_dir + \"pixel_values.csv\",sep=',')\n",
    "ground_motion_pxl = np.array(ground_motion_pxl)\n",
    "\n",
    "# the first column only has indices - we don't need that.\n",
    "ground_motion_pxl = ground_motion_pxl[:,1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### read concatenated ground motion data ##################\n",
    "concat_ground_motion_pxl = pd.read_csv(concatenated_file)\n",
    "concat_ground_motion_pxl = np.array(concat_ground_motion_pxl)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### read distance to road data ###############\n",
    "road_distances = pd.read_csv(ground_motion_dir + \"road_distances.csv\",sep=',')\n",
    "road_distances = np.array(road_distances)\n",
    "\n",
    "# the first column only has indices - we don't need that.\n",
    "road_distances = road_distances[:,1:]\n",
    "\n",
    "# convert into dataframe so that we can merge later - not the keys have the be the same for the 2 df to merge.\n",
    "road_distances_df = pd.DataFrame({'rows': road_distances[:,0],'cols': road_distances[:,1], 'distance_to_road':road_distances[:,2]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert timeseries into dataframe\n",
    "concat_ground_motion_df = pd.DataFrame({'ground_motion': concat_ground_motion_pxl[:, 0], 'time_of_motion': concat_ground_motion_pxl[:, 1], 'slope': concat_ground_motion_pxl[:,2], 'rows': concat_ground_motion_pxl[:,3],'cols': concat_ground_motion_pxl[:,4]})\n",
    "print(concat_ground_motion_df.head())\n",
    "\n",
    "# merge the road distance and the ground motion timeseries dataframes.\n",
    "result = pd.merge(concat_ground_motion_df, road_distances_df, how='inner', on=['rows', 'cols'])\n",
    "\n",
    "result.to_csv(ground_motion_dir+'merged_result.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
