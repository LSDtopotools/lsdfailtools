:numbered:


== Monte Carlo analysis to constrain the model

The Monte-Carlo analysis requires running a large (>10000) number of simulations in order to produce representative results. The software uses `python` as scripting language to automate the simulations and save/load/process the data. The installation section explains how to set up a `python` environment. The environment must be used to run python scripts. The Monte Carlo analysis is designed to define ranges of each of the 9 parameters in the model. It does this by running simulations that randomly sample these parameters within a predifined parameter space, and testing the resulting factor of safety time series against observed ground motion. The advantage is that running all the combinations would take several years of computation, whereas random sampling covers most of the spectrum in significantly less simulations.

=== Building the model

The model needs to be initialised with ranges of parameters as follow:

[source,python]
----
from plot_iverson_lsdtt import MonteCarloIverson

my_simulation = MonteCarloIverson(range_D_0 = [1e-8,1e-4], range_Ksat = [1e-11,1e-6],range_Iz_over_K_steady = [0.1,1.5], range_d = [0.5,3], range_alpha = [0.1,1.5], range_friction_angle = [0.1,1],
        range_cohesion = [100,5000], range_weight_of_soil = [15000,30000], range_weight_of_water = [9800,9800], depth_spacing = 0.1, n_depths = 35, OMS_D_0 = 1.,OMS_Ksat = 1., OMS_d = 0.1 , OMS_alpha = 0.1, OMS_friction_angle = 0.05, OMS_cohesion = 100,OMS_weight_of_soil = 500,OMS_weight_of_water = 100, OMS_Iz_over_Kz = 0.1,
        program = "", path_to_rainfall_csv = "./", rainfall_csv = "preprocessed_data.csv", path_to_root_analysis = "./", suffix = 0)
----

Most of the parameters are self-explanatory: `range_X` define the minimum and maximum values for the corresponding parameter; `OMS_X` define the precision step of the random sampling (`D_0` and `Ksat` are in log space); `n_depths` defines the number of depth to be investigated, `program` points to the path+name of the `exe` file (compiled model); `path_to_rainfall_csv` and `rainfall_csv` points to the rainfall csv file and finally `path_to_root_analysis` points to the root directory of the analysis (many subdirectories may be created below). The parameter `suffix` is set to `0` if you enter the full `csv` filename with extension. If this is `1` it assumes the extension is `csv`. Of the parameters, there should be no range for the `weight_of_water` as this is just the density of water times gravitational acceleration and does not vary. 

=== Running the simulation

To run the simulation, simply add the following line of code on the script above that contains the ranges:

[source,python]
----
my_simulation.run_MonteCarlo(failure_time_s = 540460, n_proc = 4, n_tests = 1000)
----

Where `failure_time_s` is an optional feature if a specific time is chased: it would add a data to the output expressing the time of first failure compare to that one (it does not affect the other outputs); `n_proc` defines the number of processors to be used in parallel: the code is pleasingly parallel which means all the tasks are independent from each others and can be run at the same time; `n_test` defines the number of simulations to run. For example, we ran 70000 simulation on 24 cores on our server with a broad range of parameter taken from literature with the following script:

[source,python]
----

from plot_iverson_lsdtt.sensitivity_analysis import MonteCarloIverson

program = "/home/s1675537/PhD/DataStoreBoris/dev_LSD/LSDTT_Development/src/Analysis_driver/Iverson.exe"
MySim = MonteCarloIverson(program = program, path_to_rainfall_csv = "./", rainfall_csv = "preprocessed_data.csv", path_to_root_analysis = "./test_from_in_situ/", depth_spacing = 0.1,
	n_depths = 32, range_D_0 = [5e-7,5e-5], range_Ksat = [5e-10,5e-7],range_Iz_over_K_steady = [0.1,0.8], range_d = [1,3], range_alpha = [0.5,1.1], range_friction_angle = [0.3,0.5],
        range_cohesion = [15500,16500], range_weight_of_soil = [15000,20000], range_weight_of_water = [9800,9800],
        OMS_D_0 = 0.05,OMS_Ksat = 0.05, OMS_d = 0.05, OMS_alpha = 0.05, OMS_friction_angle = 0.03, OMS_cohesion = 100,OMS_weight_of_soil = 100,OMS_weight_of_water = 100, OMS_Iz_over_Kz = 0.05)

MySim.run_MonteCarlo(failure_time_s = 0, n_proc = 24, n_tests = 200000, save_to_db = True)

----


=== Outputs

WARNING: While the model is running, a significant amount of temporary output data will be generated. This is due to the fact that the model write some results to the disk before appending them every `n_proc` runs in a final file. Do not delete it as the software does it automatically.

The most important output is a `csv` file (that can be opened by any common software) named `failure_global.csv`. It contains a synthesis of each simulation with (i) the parameters tested and (ii) the time of failure. It allowed us to produce the histograms of time of failure and isolate successful parameters.

Another file is generated containing more details about each run (time series): because of the significant amount of data produced by the simulations, the software uses the `hdf5` data structure via `pandas` to manage it. We strongly advice to use `pandas` in `python` to explore the data. One can open a file with the list of keys as follow:

[source,python]
----
import pandas as pd

glob = pd.HDFStore("test_from_in_situ/db_of_failure.hd5")
print(glob.keys())
glob.close()
----

WARNING: It will display a lot of keys and might take time...

To access the dataframe of one single run and potentially save it for more data mining:

[source,python]
----
import pandas as pd

glob = pd.HDFStore("test_from_in_situ/db_of_failure.hd5")
df = glob["name_of_my_key"]
df.to_csv("/path/plus/name.csv", index = False)
glob.close()
----


=== Performance

Assessing performance can be difficult: due to the high number of simulations run within the Monte Carlo framework, there are many unsucessful simulations, but the general pattern still highlights the failure quite well. The following code produces first order performance metrics based on the file produced by the `python` package. It takes the time of observed failures and an interval to calculate the ratio of successful simulations. It can be used to isolate the successful combination of parameters that lead to real failures.

[source,python]
----
import pandas as pd

# Load the dataframe
df = pd.read_csv("failure_global.csv")

# Gater the interval
sttest = []
endtt = []
interval = 3600 * 24 * 5 # 5 days to seconds
for i in [1.1e7,1.48e7,1.85e7,2e7]: # this array contains the times of observed failure in seconds
	sttest.append(i - interval)
	endtt.append(i + interval)

# number of elements
n_total = df.shape[0]

# Sorting my failure times to isolate the successful ones
lsofdf = []
for i in range(len(sttest)):
	lsofdf.append(df[(df["first_failure"]>sttest[i]) & (df["first_failure"]<endtt[i])] )
QDF = pd.concat(lsofdf)

# printing the results

print("Total number of run: %s " %(n_total))
print("Total number of successful run: %s " %(QDF.shape[0]))
print("Total number of run showing constant failure: %s " %(df[df["first_failure"]==0].shape[0]))
print("Ratio of success: %s " %(QDF.shape[0]/n_total ))
print("Ratio of success ignoring 0: %s " %( QDF.shape[0] / ( df[df["first_failure"]!=0].shape[0]) ) )
----
